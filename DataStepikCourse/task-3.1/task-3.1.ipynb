{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом практическом задании мы поработаем с алгоритмом линейной регрессии и нормализацией признаков. Для начала загрузите данные из файла `data.csv`, который содержит 100 признаков f1, f2, ..., f100 и целевую переменную target. Для загрузки данных используете функцию `read_csv` из библиотеки `pandas`. Выделите матрицу признаков и целевую переменную из загруженных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data.csv')\n",
    "#data, target = data.loc[:,'f1':'f100'], data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, разделите загруженный датасет на тренировочную и тестовую выборку. Для этого используйте функцию `train_test_split` из модуля `sklearn.model_selection` с параметрами `random_state=42` и `test_size=0.33`. Обучите линейную регрессию на тренировочных данных и оцените среднеквадратическую ошибку на тестовых данных. Один из вариантов линейной регрессии в `scikit-learn` представлен классом `Ridge` из `sklearn.linear_model`.\n",
    "Используйте параметр `random_state=42` в конструкторе класса при создании его экземпляра. Оценку среднеквадратичной ошибки проведите с помощью функции `mean_squared_error` из модуля `sklearn.metrics`. В качестве ответа `answer1` приведите это значение округлённое с точностью до двух знаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "data_train, data_test = train_test_split(data,random_state = 42, test_size = 0.33)\n",
    "reg_train = Ridge(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, target_train = data_train.loc[:,'f1':'f100'], data_train['target']\n",
    "reg_train.fit(train,target_train)\n",
    "test, target_test = data_test.loc[:,'f1':'f100'], data_test['target']\n",
    "answer1 = mean_squared_error(target_test,reg_train.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее вам предлагается стандартизовать данные используя `StandardScaler` из `sklearn.preprocessing`. По своей сути операция стандартизации в данном случае представляет из себя вычитание среднего из матрицы признаков и деление на среднеквадратическое отклонение. \n",
    "\n",
    "<font color  = \"red\">Важно:</font> Сначала следует разбить выборку на тренировочную и тестовую и лишь потом стандартизировать их по отдельности. Помните, что к тренировочной выборке мы должны применять метод `fit_transform()`, а к тестовой только `transform()`. Как изменилось качество на тестовых данных? В `answer2` запишите значение среднеквадратической ошибки, округлённое с точностью до двух знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.31886791e+00, -6.32210340e-01, -3.43231231e+00, -6.77363071e+00,\n",
       "       -8.67231369e+00, -5.18571003e+00, -4.53457764e-01,  3.80572509e+01,\n",
       "        2.35001245e+00, -4.93787884e-01,  4.89824957e+00,  1.94581952e+00,\n",
       "        1.95468349e+00,  2.25123023e+00, -2.88706173e+00, -3.29336565e+00,\n",
       "       -1.45278451e+00, -4.20537659e+00,  2.92143636e+00,  3.26459396e+00,\n",
       "       -7.62883695e+00, -1.01049091e+01,  4.65033981e+01,  1.84775458e+00,\n",
       "        4.27106465e+00,  7.09254217e+00,  5.48055998e-02,  1.00345183e+00,\n",
       "        1.56906515e+01,  2.37772087e+00,  2.83442176e-01, -8.46075185e+00,\n",
       "        5.63551721e+01,  1.71352254e+00, -2.73464671e+00, -9.63056811e+00,\n",
       "       -3.53686247e+00,  1.50437344e+01,  6.49141022e-01, -2.82325835e+00,\n",
       "        1.03446810e+00, -3.99662650e+00, -7.71908352e+00, -5.82309282e+00,\n",
       "       -9.43140249e-02,  5.92482023e+00,  2.71613854e+00,  1.13468829e-01,\n",
       "       -1.28142503e+01, -6.78656725e+00, -2.09223112e+00, -2.80645050e+00,\n",
       "       -1.38655222e+00,  6.64863925e+01,  3.25273533e+00,  4.23366936e+00,\n",
       "       -2.61002960e+00, -3.73597918e+00,  5.22942819e+00,  3.28926534e+00,\n",
       "        9.18766494e+00,  3.28213907e+00,  7.99308569e+00, -6.75060578e+00,\n",
       "       -4.59674716e+00, -1.09692255e+00,  3.02098592e+00, -3.56197778e+00,\n",
       "        1.69093873e+01,  4.04983011e+00, -1.61435458e+00, -9.78835446e+00,\n",
       "        8.52339057e+00, -1.17629142e+01, -8.99790250e-01, -1.99240346e+00,\n",
       "        2.22118684e+00,  4.25839967e+00, -2.83857000e+00,  8.17001792e-01,\n",
       "        2.74423608e+00, -3.55351392e+00,  4.47486009e-01,  4.10423716e+01,\n",
       "       -6.11170284e+00, -4.01365290e+00, -2.86788648e+00,  1.51986346e+01,\n",
       "       -2.22557142e-01, -1.34276078e+00, -3.33537537e+00,  1.78342631e+01,\n",
       "        3.75462330e+00, -6.53124275e+00,  2.01608425e+00,  5.46110891e+00,\n",
       "       -5.33809225e+00,  2.20114938e+00,  2.34252385e+00,  4.57609536e+00])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler  = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "#target_train = scaler.fit_transform(target_train)\n",
    "#target_test  = scaler.transform(target_test)\n",
    "model = reg_train.fit(train,target_train)\n",
    "answer2 = mean_squared_error(target_test, model.predict(test))\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строка с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 1: 4921.83\n",
      "mse 2: 4195.00\n"
     ]
    }
   ],
   "source": [
    "print('mse 1: {0:.2f}\\nmse 2: {1:.2f}'.format(answer1, answer2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
